# voice-assistant/docker-compose.yml
services:
  asr:
    build:
      context: ./backend/asr
      dockerfile: Dockerfile
    container_name: voice-assistant-asr
    ports:
      - "${ASR_PORT}:${ASR_PORT}"
    volumes:
      - ./shared/config.yaml:/app/config.yaml:ro
      - ./shared/logs:/app/logs
      - model_cache:${CACHE_DIR:-/cache}
    environment:
      - ASR_PORT=${ASR_PORT}
      - CACHE_DIR=${CACHE_DIR:-/cache}
      - USE_GPU=${USE_GPU}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - PYTHONUNBUFFERED=${PYTHONUNBUFFERED:-1}
      - CONFIG_PATH=/app/config.yaml
      - LOG_FILE_BASE=/app/logs/service
      - HUGGING_FACE_TOKEN=${HUGGING_FACE_TOKEN}
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              count: 1
    runtime: nvidia
    networks:
      - voice-assistant-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:${ASR_PORT}/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

  llm:
    build:
      context: ./backend/llm
      dockerfile: Dockerfile
    container_name: voice-assistant-llm
    ports:
      - "${LLM_PORT}:${LLM_PORT}"
    volumes:
      - ./shared/config.yaml:/app/config.yaml:ro
      - ./shared/logs:/app/logs
      - model_cache:${CACHE_DIR:-/cache}
    environment:
      - LLM_PORT=${LLM_PORT}
      - CACHE_DIR=${CACHE_DIR:-/cache}
      - USE_GPU=${USE_GPU}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - PYTHONUNBUFFERED=${PYTHONUNBUFFERED:-1}
      - CONFIG_PATH=/app/config.yaml
      - LOG_FILE_BASE=/app/logs/service
      - HUGGING_FACE_TOKEN=${HUGGING_FACE_TOKEN}
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CMAKE_ARGS=${CMAKE_ARGS:--DLLAMA_CUBLAS=on}
      - FORCE_CMAKE=${FORCE_CMAKE:-1}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              count: 1
    runtime: nvidia
    networks:
      - voice-assistant-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:${LLM_PORT}/health"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 180s

  tts:
    build:
      context: ./backend/tts
      # Ensure the Dockerfile includes websocat installation
      dockerfile: Dockerfile
    container_name: voice-assistant-tts
    ports:
      - "${TTS_PORT}:${TTS_PORT}"
    volumes:
      - ./shared/config.yaml:/app/config.yaml:ro
      - ./shared/logs:/app/logs
      - model_cache:${CACHE_DIR:-/cache}
    environment:
      - TTS_PORT=${TTS_PORT}
      - CACHE_DIR=${CACHE_DIR:-/cache}
      - USE_GPU=${USE_GPU} # Should be true or auto for CSM
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - PYTHONUNBUFFERED=${PYTHONUNBUFFERED:-1}
      - CONFIG_PATH=/app/config.yaml
      - LOG_FILE_BASE=/app/logs/service
      - HUGGING_FACE_TOKEN=${HUGGING_FACE_TOKEN} # REQUIRED
      - TTS_SPEAKER_ID=${TTS_SPEAKER_ID:-4} # Default to 4 for expressiva model
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - HF_HOME=${CACHE_DIR:-/cache}/huggingface # Explicitly set HF_HOME
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              count: 1 # CSM requires GPU
    runtime: nvidia
    networks:
      - voice-assistant-net
    restart: unless-stopped
    # --- UPDATED HEALTHCHECK SECTION for TTS using /ws_health ---
    healthcheck:
      test: >
        sh -c '
          curl --fail -s http://localhost:${TTS_PORT}/health &&
          websocat -q --one-message ws://localhost:${TTS_PORT}/ws_health
        '
        # -q: quiet mode
        # --one-message: waits for exactly one message OR EOF (which /ws_health sends immediately after accept)
      interval: 15s   # Check slightly more often
      timeout: 10s    # Overall timeout for the sh -c command
      retries: 6      # Increase retries slightly
      start_period: 300s # Keep long start period for model loading
    # --- END OF UPDATED HEALTHCHECK ---

  orchestrator:
    build:
      context: ./backend/orchestrator
      dockerfile: Dockerfile
    container_name: voice-assistant-orchestrator
    ports:
      - "${ORCHESTRATOR_PORT}:${ORCHESTRATOR_PORT}"
    volumes:
      - ./shared/config.yaml:/app/config.yaml:ro
      - ./shared/logs:/app/logs
    environment:
      - ORCHESTRATOR_PORT=${ORCHESTRATOR_PORT}
      - ASR_SERVICE_URL=http://asr:${ASR_PORT}
      - LLM_SERVICE_URL=http://llm:${LLM_PORT}
      - TTS_SERVICE_URL=http://tts:${TTS_PORT}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - PYTHONUNBUFFERED=${PYTHONUNBUFFERED:-1}
      - CONFIG_PATH=/app/config.yaml
      - LOG_FILE_BASE=/app/logs/service
    depends_on: # This correctly waits for the updated healthcheck now
      asr:
        condition: service_healthy
      llm:
        condition: service_healthy
      tts:
        condition: service_healthy
    networks:
      - voice-assistant-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:${ORCHESTRATOR_PORT}/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s # Orchestrator itself starts fast

networks:
  voice-assistant-net:
    driver: bridge

volumes:
  model_cache:
    driver: local
